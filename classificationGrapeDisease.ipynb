{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = 'E:\\\\Document\\\\HK2-2022-2023\\\\DIPR\\\\Project\\\\research\\\\GrapeDiseaseDataset\\\\OriginalData\\\\train'\n",
    "test_dir = 'E:\\\\Document\\\\HK2-2022-2023\\\\DIPR\\\\Project\\\\research\\\\GrapeDiseaseDataset\\\\OriginalData\\\\test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7222 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1805 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second test model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# Stage 1\n",
    "x = tf.keras.layers.Conv2D(64, (7,7), strides=(2,2), padding='same')(inputs)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "# Stage 2\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(64, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "# Stage 3\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(128, (1,1), strides=(2,2), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(512, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(512, (1,1), strides=(2,2), padding='valid')(shortcut)\n",
    "if x.shape != shortcut.shape:\n",
    "    shortcut = tf.keras.layers.Conv2D(512, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "#Stage 4\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(256, (1,1), strides=(2,2), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(1024, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(1024, (1,1), strides=(2,2), padding='valid')(shortcut)\n",
    "if x.shape != shortcut.shape:\n",
    "    shortcut = tf.keras.layers.Conv2D(1024, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "#Stage 5\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(512, (1,1), strides=(2,2), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(512, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(2048, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(2048, (1,1), strides=(2,2), padding='valid')(shortcut)\n",
    "if x.shape != shortcut.shape:\n",
    "    shortcut = tf.keras.layers.Conv2D(2048, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "#Final layers\n",
    "x = tf.keras.layers.AveragePooling2D((7, 7))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "#Create Model\n",
    "model = None\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input shape\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "# Define the number of classes\n",
    "num_classes = 4\n",
    "\n",
    "# Define the model architecture\n",
    "inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "# Stage 1\n",
    "x = tf.keras.layers.Conv2D(64, (7,7), strides=(2,2), padding='same')(inputs)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
    "\n",
    "# Stage 2\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(64, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(256, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "# Stage 3\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(128, (1,1), strides=(2,2), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(512, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(512, (1,1), strides=(2,2), padding='valid')(shortcut)\n",
    "if x.shape != shortcut.shape:\n",
    "    shortcut = tf.keras.layers.Conv2D(512, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "#Stage 4\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(256, (1,1), strides=(2,2), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(1024, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(1024, (1,1), strides=(2,2), padding='valid')(shortcut)\n",
    "if x.shape != shortcut.shape:\n",
    "    shortcut = tf.keras.layers.Conv2D(1024, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "#Stage 5\n",
    "shortcut = x\n",
    "x = tf.keras.layers.Conv2D(512, (1,1), strides=(2,2), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(512, (3,3), strides=(1,1), padding='same')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Conv2D(2048, (1,1), strides=(1,1), padding='valid')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "shortcut = tf.keras.layers.Conv2D(2048, (1,1), strides=(2,2), padding='valid')(shortcut)\n",
    "if x.shape != shortcut.shape:\n",
    "    shortcut = tf.keras.layers.Conv2D(2048, (1,1), strides=(1,1), padding='valid')(shortcut)\n",
    "x = tf.keras.layers.Add()([x, shortcut])\n",
    "x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "# Final layers\n",
    "x = tf.keras.layers.AveragePooling2D((7, 7))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "#Create Model\n",
    "model = None\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TVD\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py:5531: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/226 [==============================] - 144s 615ms/step - loss: 0.5014 - accuracy: 0.8272 - val_loss: 11.1346 - val_accuracy: 0.3025\n",
      "Epoch 2/50\n",
      "226/226 [==============================] - 88s 389ms/step - loss: 0.2400 - accuracy: 0.9133 - val_loss: 5.9220 - val_accuracy: 0.5169\n",
      "Epoch 3/50\n",
      "226/226 [==============================] - 89s 392ms/step - loss: 0.1638 - accuracy: 0.9420 - val_loss: 3.4079 - val_accuracy: 0.3524\n",
      "Epoch 4/50\n",
      "226/226 [==============================] - 90s 399ms/step - loss: 0.1438 - accuracy: 0.9495 - val_loss: 31.2247 - val_accuracy: 0.3745\n",
      "Epoch 5/50\n",
      "226/226 [==============================] - 89s 393ms/step - loss: 0.1175 - accuracy: 0.9597 - val_loss: 6.4138 - val_accuracy: 0.6305\n",
      "Epoch 6/50\n",
      "226/226 [==============================] - 91s 404ms/step - loss: 0.1072 - accuracy: 0.9636 - val_loss: 2.5214 - val_accuracy: 0.6510\n",
      "Epoch 7/50\n",
      "226/226 [==============================] - 91s 400ms/step - loss: 0.0668 - accuracy: 0.9785 - val_loss: 0.9579 - val_accuracy: 0.8000\n",
      "Epoch 8/50\n",
      "226/226 [==============================] - 92s 406ms/step - loss: 0.0887 - accuracy: 0.9698 - val_loss: 2.2240 - val_accuracy: 0.5313\n",
      "Epoch 9/50\n",
      "226/226 [==============================] - 90s 396ms/step - loss: 0.0753 - accuracy: 0.9776 - val_loss: 15.5238 - val_accuracy: 0.4859\n",
      "Epoch 10/50\n",
      "226/226 [==============================] - 94s 416ms/step - loss: 0.0677 - accuracy: 0.9759 - val_loss: 3.7271 - val_accuracy: 0.5756\n",
      "Epoch 11/50\n",
      "226/226 [==============================] - 92s 407ms/step - loss: 0.0597 - accuracy: 0.9808 - val_loss: 3.5995 - val_accuracy: 0.5291\n",
      "Epoch 12/50\n",
      "226/226 [==============================] - 90s 395ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.1969 - val_accuracy: 0.9485\n",
      "Epoch 13/50\n",
      "226/226 [==============================] - 91s 403ms/step - loss: 0.0395 - accuracy: 0.9856 - val_loss: 5.1169 - val_accuracy: 0.5751\n",
      "Epoch 14/50\n",
      "226/226 [==============================] - 90s 395ms/step - loss: 0.0590 - accuracy: 0.9813 - val_loss: 2.0302 - val_accuracy: 0.5407\n",
      "Epoch 15/50\n",
      "226/226 [==============================] - 91s 402ms/step - loss: 0.0969 - accuracy: 0.9675 - val_loss: 2.8040 - val_accuracy: 0.6022\n",
      "Epoch 16/50\n",
      "226/226 [==============================] - 96s 425ms/step - loss: 0.0510 - accuracy: 0.9819 - val_loss: 1.2322 - val_accuracy: 0.7163\n",
      "Epoch 17/50\n",
      "226/226 [==============================] - 94s 414ms/step - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.4474 - val_accuracy: 0.8781\n",
      "Epoch 18/50\n",
      "226/226 [==============================] - 95s 419ms/step - loss: 0.0396 - accuracy: 0.9864 - val_loss: 0.1783 - val_accuracy: 0.9562\n",
      "Epoch 19/50\n",
      "226/226 [==============================] - 93s 412ms/step - loss: 0.0420 - accuracy: 0.9862 - val_loss: 4.9539 - val_accuracy: 0.3889\n",
      "Epoch 20/50\n",
      "226/226 [==============================] - 91s 400ms/step - loss: 0.0355 - accuracy: 0.9873 - val_loss: 0.0758 - val_accuracy: 0.9795\n",
      "Epoch 21/50\n",
      "226/226 [==============================] - 90s 398ms/step - loss: 0.0499 - accuracy: 0.9832 - val_loss: 2.3199 - val_accuracy: 0.6925\n",
      "Epoch 22/50\n",
      "226/226 [==============================] - 92s 408ms/step - loss: 0.0328 - accuracy: 0.9881 - val_loss: 2.5749 - val_accuracy: 0.6006\n",
      "Epoch 23/50\n",
      "226/226 [==============================] - 92s 405ms/step - loss: 0.0515 - accuracy: 0.9842 - val_loss: 1.0444 - val_accuracy: 0.7529\n",
      "Epoch 24/50\n",
      "226/226 [==============================] - 92s 406ms/step - loss: 0.0538 - accuracy: 0.9831 - val_loss: 2.0241 - val_accuracy: 0.6665\n",
      "Epoch 25/50\n",
      "226/226 [==============================] - 86s 377ms/step - loss: 0.0266 - accuracy: 0.9910 - val_loss: 0.1285 - val_accuracy: 0.9618\n",
      "Epoch 26/50\n",
      "226/226 [==============================] - 85s 377ms/step - loss: 0.0314 - accuracy: 0.9885 - val_loss: 0.3559 - val_accuracy: 0.9335\n",
      "Epoch 27/50\n",
      "226/226 [==============================] - 90s 398ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.0485 - val_accuracy: 0.9828\n",
      "Epoch 28/50\n",
      "226/226 [==============================] - 115s 507ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 0.2973 - val_accuracy: 0.9307\n",
      "Epoch 29/50\n",
      "226/226 [==============================] - 87s 382ms/step - loss: 0.0297 - accuracy: 0.9907 - val_loss: 32.1584 - val_accuracy: 0.3169\n",
      "Epoch 30/50\n",
      "226/226 [==============================] - 84s 371ms/step - loss: 0.0378 - accuracy: 0.9870 - val_loss: 0.6553 - val_accuracy: 0.8914\n",
      "Epoch 31/50\n",
      "226/226 [==============================] - 85s 375ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 1.6649 - val_accuracy: 0.7673\n",
      "Epoch 32/50\n",
      "226/226 [==============================] - 85s 374ms/step - loss: 0.0279 - accuracy: 0.9931 - val_loss: 22.8414 - val_accuracy: 0.2709\n",
      "Epoch 33/50\n",
      "226/226 [==============================] - 84s 372ms/step - loss: 0.0427 - accuracy: 0.9853 - val_loss: 0.1688 - val_accuracy: 0.9607\n",
      "Epoch 34/50\n",
      "226/226 [==============================] - 85s 377ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0509 - val_accuracy: 0.9867\n",
      "Epoch 35/50\n",
      "226/226 [==============================] - 85s 376ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 2.3619 - val_accuracy: 0.6150\n",
      "Epoch 36/50\n",
      "226/226 [==============================] - 85s 374ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.2019 - val_accuracy: 0.9418\n",
      "Epoch 37/50\n",
      "226/226 [==============================] - 86s 378ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.4019 - val_accuracy: 0.8593\n",
      "Epoch 38/50\n",
      "226/226 [==============================] - 85s 376ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0106 - val_accuracy: 0.9967\n",
      "Epoch 39/50\n",
      "226/226 [==============================] - 84s 373ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.4105 - val_accuracy: 0.9008\n",
      "Epoch 40/50\n",
      "226/226 [==============================] - 85s 373ms/step - loss: 0.0264 - accuracy: 0.9925 - val_loss: 0.0493 - val_accuracy: 0.9861\n",
      "Epoch 41/50\n",
      "226/226 [==============================] - 85s 373ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.7685 - val_accuracy: 0.8460\n",
      "Epoch 42/50\n",
      "226/226 [==============================] - 85s 375ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 0.5358 - val_accuracy: 0.8842\n",
      "Epoch 43/50\n",
      "226/226 [==============================] - 84s 373ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.2117 - val_accuracy: 0.9280\n",
      "Epoch 44/50\n",
      "226/226 [==============================] - 84s 372ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 1.0333 - val_accuracy: 0.8183\n",
      "Epoch 45/50\n",
      "226/226 [==============================] - 86s 379ms/step - loss: 0.0160 - accuracy: 0.9952 - val_loss: 0.0563 - val_accuracy: 0.9839\n",
      "Epoch 46/50\n",
      "226/226 [==============================] - 85s 373ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.1422 - val_accuracy: 0.9651\n",
      "Epoch 47/50\n",
      "226/226 [==============================] - 85s 374ms/step - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.6082 - val_accuracy: 0.8704\n",
      "Epoch 48/50\n",
      "226/226 [==============================] - 85s 374ms/step - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.0217 - val_accuracy: 0.9917\n",
      "Epoch 49/50\n",
      "226/226 [==============================] - 84s 373ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.0302 - val_accuracy: 0.9884\n",
      "Epoch 50/50\n",
      "226/226 [==============================] - 84s 372ms/step - loss: 0.0165 - accuracy: 0.9958 - val_loss: 0.0690 - val_accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=test_generator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 5s 79ms/step - loss: 0.0690 - accuracy: 0.9789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06896321475505829, 0.9789473414421082]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a .h5 file\n",
    "model.save('my_trained_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a .h5 file\n",
    "model.save('my_trained_model2.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a .h5 file\n",
    "model.save('my_trained_model3.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save ResNet with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model as a .h5 file\n",
    "model.save('my_trained_model4.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save ResNet with dropout 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_trained_model5.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "\n",
    "# variable\n",
    "file_path = None\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('my_trained_model5.h5')\n",
    "img_height = img_width = 256\n",
    "# Define the class names\n",
    "class_names = ['Black Rot', 'ESCA', 'Healthy', 'Leaf Blight', ...]\n",
    "\n",
    "# Create a function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    # Resize the image to match the input size of the model\n",
    "    image = image.resize((img_height, img_width))\n",
    "    # Convert the image to a numpy array\n",
    "    image_array = np.array(image)\n",
    "    # Normalize the pixel values to be between 0 and 1\n",
    "    image_array = image_array / 255.0\n",
    "    # Expand the dimensions of the image to match the input shape of the model\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    return image_array\n",
    "\n",
    "# Create a function to classify the image\n",
    "def classify_image():\n",
    "    global file_path\n",
    "    if file_path == None:\n",
    "        # Show an error message if there was a problem loading the image\n",
    "        messagebox.showerror('Error', 'Please upload image!')\n",
    "    # Load the image\n",
    "    image = Image.open(file_path)\n",
    "    # Preprocess the image\n",
    "    image_array = preprocess_image(image)\n",
    "    # Use the model to make predictions\n",
    "    predictions = model.predict(image_array)\n",
    "    model.evaluate(image_array)\n",
    "    # # Get the class with the highest probability\n",
    "    # predicted_class = np.argmax(predictions[0])\n",
    "    # # Get the class name\n",
    "    # class_name = class_names[predicted_class]\n",
    "    # # Get the probability of the predicted class\n",
    "    # class_prob = np.max(predictions[0])\n",
    "    # Show a message box with the predicted class and percentage\n",
    "    canvasInfor.delete('all')\n",
    "    text = canvasInfor.create_text(90, 80, anchor=tk.CENTER, text = \"Predict information \\n Black Rot: {0}% \\n ESCA: {1}% \\n Healthy: {2}% \\n Leaf Blight: {3}%\".format(round( predictions[0][0]*100, 2),round( predictions[0][1]*100, 2),round( predictions[0][2]*100, 2),round( predictions[0][3]*100, 2)), font=(\"Arial\", 14))\n",
    "    # messagebox.showinfo('Classification Result', f'The image is classified as {class_name} with {class_prob} probability.')\n",
    "\n",
    "# Create a function to handle the upload button click\n",
    "def handle_upload():\n",
    "    # Open a file dialog to select the image file\n",
    "    global file_path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    # Check if a file was selected\n",
    "    if file_path:\n",
    "        try:\n",
    "            # Load the image and display it in the GUI\n",
    "            image = Image.open(file_path)\n",
    "            image = image.resize((400, 400))\n",
    "            image_tk = ImageTk.PhotoImage(image)\n",
    "            canvas.itemconfig(canvas_image, image=image_tk)\n",
    "            canvas.image = image_tk\n",
    "        except:\n",
    "            # Show an error message if there was a problem loading the image\n",
    "            messagebox.showerror('Error', 'Could not open the image file.')\n",
    "\n",
    "# Create the GUI window\n",
    "window = tk.Tk()\n",
    "window.title('Image Classifier')\n",
    "window.geometry(\"900x650\")\n",
    "\n",
    "# Create a canvas to display banner\n",
    "canvasBanner = tk.Canvas(window, width=900, height=180)\n",
    "canvasBanner.place(x=0, y = 0)\n",
    "canvas_imageBanner = canvasBanner.create_image(0, 0, anchor=tk.NW)\n",
    "imageBanner = Image.open(\"./banner.png\")\n",
    "imageBanner = imageBanner.resize((900, 180))\n",
    "image_tk = ImageTk.PhotoImage(imageBanner)\n",
    "canvasBanner.itemconfig(canvas_imageBanner, image=image_tk)\n",
    "canvasBanner.image = image_tk\n",
    "\n",
    "# Create a canvas to display the image\n",
    "canvas = tk.Canvas(window, width=400, height=400, bd=2, relief='solid')\n",
    "canvas.place(x=50, y = 100 + 100)\n",
    "canvas_image = canvas.create_image(0, 0, anchor=tk.NW)\n",
    "\n",
    "# Create a canvas to display infor\n",
    "canvasInfor = tk.Canvas(window, width=200, height=400, bd=1, relief='solid')\n",
    "canvasInfor.place(x=500, y = 100 + 100)\n",
    "\n",
    "# Create a button to upload the image\n",
    "upload_button = tk.Button(window, text='Upload Image', command=handle_upload, width=12)\n",
    "upload_button.place(x=760, y = 100 + 100)\n",
    "\n",
    "classify_button = tk.Button(window, text='Classify', command=classify_image, width=12)\n",
    "classify_button.place(x=760, y = 200 + 100)\n",
    "\n",
    "# create a label\n",
    "label = tk.Label(window, text=\"Select an model:\")\n",
    "label.place(x=760, y = 300 + 100)\n",
    "\n",
    "# create a variable to hold the selected option\n",
    "selected_option = tk.StringVar(window)\n",
    "\n",
    "# set the default value of the variable\n",
    "selected_option.set(\"ResNet 50 with dropout\")\n",
    "\n",
    "# create a selection box (option menu)\n",
    "options = [\"ResNet 50 with dropout\", \"ResNet 50\", \"Basic CNN\", \"Basic CNN with dropout\", \"ResNet 50 - imagenet\"]\n",
    "option_menu = tk.OptionMenu(window, selected_option, *options)\n",
    "option_menu.config(width=23)\n",
    "option_menu.place(x=710, y = 350 + 100)\n",
    "def on_option_changed(*args):\n",
    "    global model\n",
    "    # get the new selected option\n",
    "    new_option = selected_option.get()\n",
    "    # do something with the new selected option\n",
    "    print(\"Selected option:\", new_option)\n",
    "    if new_option == \"ResNet 50 with dropout\":\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model('my_trained_model5.h5')\n",
    "    elif new_option == \"ResNet 50\":\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model('my_trained_model3.h5')\n",
    "    elif new_option == \"Basic CNN\":\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model('my_trained_model.h5')\n",
    "    elif new_option == \"ResNet 50 - imagenet\":\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model('grape_disease_model_1.h5')\n",
    "    else:\n",
    "        model = None\n",
    "        model = tf.keras.models.load_model('my_trained_model2.h5')\n",
    "\n",
    "# attach a trace to the selected_option variable\n",
    "selected_option.trace(\"w\", on_option_changed)\n",
    "# Start the GUI main loop\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
